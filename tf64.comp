#version 460
// We aren't using any of these, but just in case we want to later...
//#extension GL_ARB_separate_shader_objects : enable
//#extension GL_ARB_gpu_shader_int64 : enable
//#extension GL_EXT_debug_printf : enable
//#extension GL_KHR_shader_subgroup_vote : enable
#extension GL_EXT_shader_explicit_arithmetic_types_int8 : enable
//#extension GL_EXT_shader_explicit_arithmetic_types_int16 : enable
#extension GL_EXT_shader_explicit_arithmetic_types_int64 : enable
#extension GL_EXT_shader_atomic_int64: enable

//
// This is version using 64-bit based 128/192/256-bit math. Seems to be faster on nvidia than the 32-bit version.
//
// compile this file into SPIR-V with:
//   glslangValidator --target-env vulkan1.3 -V tf64.comp -o comp.spv
// or
//   glslc --target-env=vulkan1.3 tf64.comp -o comp.spv
// glslc might produce slightly faster SPIR-V for the Radeon VII
//
//
// Installing the 'vulkan-amdgpu' package will result in a significant (2.5x) performance increase.
// also, maybe the difference isn't so much when not using uint64_t math.
//

// Test for (3,5)mod8, and (0)mod(primes 3 -> 23) in one shot. From 446,185,740 potential K-values,
// a list of 72,990,720 are left to TF test on the GPU. List is an array of 32-bit uints, using
// about 278MB.  Each thread takes an offset from the list, adds it to the 96-bit base-K, then
// computes P * K * 2 + 1, which is then TF tested.
// When the entire list has been tested, K-base += M.
#define M (4 * 3L * 5 * 7 * 11 * 13 * 17 * 19 * 23)  // 446,185,740
#define M2 (29 * 31 * 37 * 41 * 43)                 //  58,642,669

#define ListN 72990720
//#define ListN 2043740170
layout (local_size_x = 64) in;

// This is allocated in HOST_VISIBLE_LOCAL memory, and is shared with host.
// it is somewhat slow, compared to DEVICE_LOCAL memory.
layout(binding = 0) buffer buf
{	
	uint64_t    P;          // input from CPU side
	uint        Init;       // If this is 0, then we setup our tables once.
	uint        L;          // threads use atomicAdd(L, 1) to get next next list index
	uint        Ll;         // Length of List
	uint        KmodM2;
	uint64_t    Z;          // used by Init for atomicAdd(Z, 1)
	uint64_t    K[2];       // base K input from CPU side
	uint64_t    Found[10][2];   // output to tell the CPU we found a K resulting in a factor
	uint        Debug[2];   // output only used for debugging
};


// This is allocated in DEVICE_LOCAL memory, not shared with host.  See CPU code to see how this is allocated.
// This is much faster to access from the shader, especially if the GPU is in a PCIx1 slot.
layout(binding = 1) buffer buf2
{
	uint       List[ListN];
	bool       X2[M2];
};

struct uint128 {
	uint64_t Hi, Lo;
};
struct uint256 {
	uint128 H, L;
};
struct uint192 {
	uint64_t H;
	uint128 L;
};

void Set(inout uint256 A, uint128 B) {
	A.L = B;
	A.H.Lo = 0;
	A.H.Hi = 0;
}
void Lsh(inout uint128 A) {
	uint64_t c = A.Lo & (uint64_t(1) << 63);
	A.Lo <<= 1;
	A.Hi <<= 1;
	A.Hi |= c >> 63;
}
void Lsh(inout uint256 A) {
	
	uint64_t c = A.L.Hi & (uint64_t(1) << 63);
	Lsh(A.L);
	Lsh(A.H);
	A.H.Lo |= c >> 63;
}
void Lsh(inout uint192 A) {
	
	uint64_t c = A.L.Hi & (uint64_t(1) << 63);
	Lsh(A.L);
	A.H <<= 1;
	A.H |= c >> 63;
}

void Rsh(inout uint128 A) {
	uint64_t b = A.Hi & 1l;
	A.Hi >>= 1;
	A.Lo >>= 1;
	A.Lo |= b << 63;
}
void Rsh(inout uint192 A) {
	Rsh(A.L);
	uint64_t b = A.H & 1l;
	A.H >>= 1;
	A.L.Hi |= b << 63;
	
}
void Rsh(inout uint256 A) {
	Rsh(A.L);
	uint64_t b = A.H.Lo & 1l;
	Rsh(A.H);
	A.L.Hi |= b << 63;
	
}
int Cmp(uint128 A, uint64_t B) {
	if (A.Hi != 0) {return 1;}
	if (A.Lo > B) {return 1;}
	if (A.Lo < B) {return -1;}
	return 0;
	
}
int Cmp(uint128 A, uint128 B) {
	if (A.Hi > B.Hi || (A.Hi == B.Hi && A.Lo > B.Lo)) {return 1;}
	if (A.Hi < B.Hi || (A.Hi == B.Hi && A.Lo < B.Lo)) {return -1;}
	return 0;
}
int Cmp(uint192 A, uint128 B) {
	if (A.H != 0) {
		return 1;
	}
	return Cmp(A.L, B);
}
int Cmp(uint192 A, uint192 B) {
	if (A.H == B.H) {
		return Cmp(A.L, B.L);
	}
	if (A.H > B.H) {
		return 1;
	}
	if (A.H < B.H) {
		return -1;
	}
}
int Cmp(uint256 A, uint128 B) {
	if (A.H.Hi != 0 || A.H.Lo != 0) {
		return 1;
	}
	return Cmp(A.L, B);
}
int Cmp(uint256 A, uint256 B) {
	int d = Cmp(A.H, B.H);
	if (d != 0) { return d; }
	return Cmp(A.L, B.L);
}
void Inc(inout uint128 A) {
	A.Lo += 1;
	if (A.Lo == 0) {
		A.Hi += 1;
	}
}
void Sub(inout uint128 A, uint128 B) {
	uint64_t x = A.Lo - B.Lo;
	uint64_t C = (((x & B.Lo) & 1l) + (B.Lo >> 1) + (x >> 1)) >> 63;
	A.Hi = A.Hi - (B.Hi + C);
	A.Lo = x;
}
void Sub(inout uint256 A, uint256 B) {
	uint64_t x = A.L.Lo - B.L.Lo;
	uint C = 0;
	if (x > A.L.Lo) {C++;}
	A.L.Lo = x;
	x = A.L.Hi - (B.L.Hi + C);
	C = 0;
	if (x > A.L.Hi) {C++;} 
	A.L.Hi = x;

	x = A.H.Lo - (B.H.Lo + C);
	C = 0;
	if (x > A.H.Lo) {C++;}
	A.H.Lo = x;

	A.H.Hi = A.H.Hi - (B.H.Hi + C);
}
void Sub(inout uint192 A, uint192 B) {
	uint64_t x = A.L.Lo - B.L.Lo;
	uint C = 0;
	if (x > A.L.Lo) {C++;}
	A.L.Lo = x;
	x = A.L.Hi - (B.L.Hi + C);
	C = 0;
	if (x > A.L.Hi) {C++;} 
	A.L.Hi = x;

	A.H = A.H - (B.H + C);
}
void Add(inout uint128 A, uint128 B) {
	uint64_t x = A.Lo + B.Lo;
	uint64_t C = 0;
	if (x < A.Lo) {C++;}
	A.Hi = A.Hi + (B.Hi + C);
	A.Lo = x;
}
bool Zero(uint128 A) {
	return A.Lo == 0 && A.Hi == 0;
}
void multiply64to128(uint64_t x, uint64_t y, out uint128 r)
{
	uint64_t lowbits = 0xfffffffful;
	u64vec4 x4 = u64vec4(x >> 32, x & lowbits, x >> 32, x & lowbits);
	u64vec4 y4 = u64vec4(y >> 32, y >> 32, y & lowbits, y & lowbits);
	u64vec4 p = x4 * y4;

	uint64_t middle = p[2] + (p[3] >> 32) + (p[1] & lowbits);
	r.Hi = p[0] + (middle >> 32) + (p[1] >> 32);
	r.Lo = (middle << 32) | (p[3] & lowbits);

	/*
	
	uint64_t p11 = (x >> 32) * (y >> 32);
	uint64_t p01 = (x & lowbits) * (y >> 32);
	uint64_t p10 = (x >> 32) * (y & lowbits);
	uint64_t p00 = (x & lowbits) * (y & lowbits);

	// 64-bit product + two 32-bit values
	uint64_t middle = p10 + (p00 >> 32) + (p01 & lowbits);

	// 64-bit product + two 32-bit values
	r.Hi = p11 + (middle >> 32) + (p01 >> 32);
	r.Lo = (middle << 32) | (p00 & lowbits);
	*/
}

void multiply64to128x(uint64_t lhs, uint64_t rhs, inout uint128 r) {

        // First calculate all of the cross products.
	uint64_t lo_lo = (lhs & 0xFFFFFFFFul) * (rhs & 0xFFFFFFFFul);
	uint64_t hi_lo = (lhs >> 32)        * (rhs & 0xFFFFFFFFul);
	uint64_t lo_hi = (lhs & 0xFFFFFFFFul) * (rhs >> 32);
	uint64_t hi_hi = (lhs >> 32)        * (rhs >> 32);

        // Now add the products together. These will never overflow.
	uint64_t cross = (lo_lo >> 32) + (hi_lo & 0xFFFFFFFFul) + lo_hi;
	uint64_t upper = (hi_lo >> 32) + (cross >> 32)        + hi_hi;

	r.Hi = upper;
	r.Lo = (cross << 32) | (lo_lo & 0xFFFFFFFFul);
}

void Mul128(uint128 A, uint64_t B, inout uint128 X) {
	multiply64to128(A.Lo, B, X);
	uint128 T;
	multiply64to128(A.Hi, B, T);
	X.Hi += T.Lo;
}
void Sq256(uint128 A, inout uint256 X) {
	multiply64to128(A.Hi, A.Hi, X.H);
	multiply64to128(A.Lo, A.Lo, X.L);

	uint128 T;
	multiply64to128(A.Hi, A.Lo, T);
	Lsh(T);

	X.L.Hi += T.Lo;
	if (X.L.Hi < T.Lo) {
		Inc(X.H);
	}
	X.H.Lo += T.Hi;
	if (X.H.Lo < T.Hi) {
		X.H.Hi++;
	}
}
void Sq192(uint128 A, inout uint192 X) {	
	X.H = A.Hi * A.Hi;
	multiply64to128(A.Lo, A.Lo, X.L);

	uint128 T;
	multiply64to128(A.Hi, A.Lo, T);
	Lsh(T);

	X.L.Hi += T.Lo;
	if (X.L.Hi < T.Lo) {
		X.H++;
	}
	X.H += T.Hi;
}
void Mul192x(uint128 A, uint128 B, out uint192 R) {
	uint64_t lb = 0xfffffffful;
	uint64_t x00 = (A.Lo & lb) * (B.Lo & lb);
	uint64_t x01 = (A.Lo & lb) * (B.Lo >> 32);
	uint64_t x02 = (A.Lo & lb) * (B.Hi & lb);
	uint64_t x10 = (A.Lo >> 32) * (B.Lo & lb);
	uint64_t x11 = (A.Lo >> 32) * (B.Lo >> 32);
	uint64_t x12 = (A.Lo >> 32) * (B.Hi & lb);
	uint64_t x20 = (A.Hi & lb) * (B.Lo & lb);
	uint64_t x21 = (A.Hi & lb) * (B.Lo >> 32);
	uint64_t x22 = (A.Hi & lb) * (B.Hi & lb);

	uint64_t m = (x00 >> 32) + x01 + (x10 & lb);
	uint64_t n = x02 + x11 + x20 + (x10 >> 32) + (m >> 32);
	uint64_t o = x12 + x21 + (n >> 32);
	R.L.Lo = (x00 & lb) | (m << 32);
	R.L.Hi = (n & lb) | (o << 32);
	R.H = (o >> 32) + x22;
}
// something suspect with this one
/*
void Sq192x(uint128 A, out uint192 R) {
	uint64_t lb = 0xfffffffful;
	uint64_t alh = A.Lo >> 32;
	uint64_t all = A.Lo & lb;
	uint64_t ahl = A.Hi & lb;
	uint64_t x00 = (all) * (all);
	uint64_t x01 = (all) * (alh);
	uint64_t x02 = (all) * (ahl);
	uint64_t x11 = (alh) * (alh);
	uint64_t x12 = (alh) * (ahl);
	uint64_t x22 = (ahl) * (ahl);

	uint64_t m = (x00 >> 32) + x01 + (x01 & lb);
	uint64_t n = x02 + x11 + x02 + (x01 >> 32) + (m >> 32);
	uint64_t o = x12 + x12  + (n >> 32);
	R.L.Lo = (x00 & lb) | (m << 32);
	R.L.Hi = (n & lb) | (o << 32);
	R.H = (o >> 32) + x22;
}
*/
void Mul192(uint128 A, uint128 B, inout uint192 X) {
	X.H = A.Hi * B.Hi;
	multiply64to128(A.Lo, B.Lo, X.L);

	uint128 T;
	multiply64to128(B.Hi, A.Lo, T);

	X.L.Hi += T.Lo;
	if (X.L.Hi < T.Lo) {
		X.H++;
	}
	X.H += T.Hi;

	multiply64to128(A.Hi, B.Lo, T);

	X.L.Hi += T.Lo;
	if (X.L.Hi < T.Lo) {
		X.H++;
	}
	X.H += T.Hi;
}
void Mul256(uint128 A, uint128 B, inout uint256 X) {
	multiply64to128(A.Hi, B.Hi, X.H);
	multiply64to128(A.Lo, B.Lo, X.L);

	uint128 T;
	multiply64to128(B.Hi, A.Lo, T);

	X.L.Hi += T.Lo;
	if (X.L.Hi < T.Lo) {
		Inc(X.H);
	}
	X.H.Lo += T.Hi;
	if (X.H.Lo < T.Hi) {
		X.H.Hi++;
	}

	multiply64to128(A.Hi, B.Lo, T);

	X.L.Hi += T.Lo;
	if (X.L.Hi < T.Lo) {
		Inc(X.H);
	}
	X.H.Lo += T.Hi;
	if (X.H.Lo < T.Hi) {
		X.H.Hi++;
	}
}
// 2^64, 2^128 and 2^192
const 	double p64 =  18446744073709551616.0lf;
const	double p128 = 340282366920938463463374607431768211456.0lf;
const	double p192 = 6277101735386680763835789423207666416102355444464034512896.0lf;

double toF(uint128 A) {
	return double(A.Lo) + double(A.Hi) * p64;
}
double toF(uint192 A) {

	return double(A.L.Lo) + double(A.L.Hi)*p64 + double(A.H)*p128;
}
double toF(uint256 A) {

	return double(A.L.Lo) + double(A.L.Hi)*p64 + double(A.H.Lo)*p128 + double(A.H.Hi)*p192;
}
void fto128(double f, out uint128 A) {
	A.Hi = uint64_t(f / p64);
	A.Lo = uint64_t(f - double(A.Hi) * p64);
}

// 256-bit Floating point version
void SqMod(inout uint128 A, uint128 Q, bool doshift, double qinv) {
	uint256 X, Y;
	uint128 D;

	Sq256(A, X);
	if (doshift) {
		Lsh(X);
	}

	int i = 0; // limit to 10, in case we have a bug, don't want to get stuck...

	// Using floating point, take a guess at a number D such that we could subtract D*Q to leave our remander.
	// Always guess D a little low, and refine our guess as we get closer.
	// normally takes 2 passes.
	while (i < 10 && Cmp(X, Q) > 0) {

		double x = toF(X);
		fto128(x*qinv, D);
		if (Zero(D)) {
			D.Lo = 1;
		}		
		Mul256(D, Q, Y);

		Sub(X, Y);
		i++;
	}
	//if (i > 3) {Debug[1]++;}
	A = X.L;
}
// 192-bit Floating point version
void SqMod9(inout uint128 A, uint128 Q, bool doshift, double qinv) {
	uint192 X, Y;
	uint128 D;

	Sq192(A, X);
	//Mul192(A, A, X);
	if (doshift) {
		Lsh(X);
	}

	int i = 0; // limit to 10, in case we have a bug, don't want to get stuck...

	// Using floating point, take a guess at a number D such that we could subtract D*Q to leave our remander.
	// Always guess D a little low, and refine our guess as we get closer.
	// normally takes 2 passes.
	//
	while (i < 10 && Cmp(X, Q) > 0) {
		double x = toF(X);
		double xqi = x*qinv;
		fto128(xqi, D);
		if (Zero(D)) {
			D.Lo = 1;
		}
		Mul192x(D, Q, Y);
		Sub(X, Y);
		i++;
	}
	//if (gl_GlobalInvocationID.x == 0 && i > 5) {Debug[1]++;}
	A = X.L;
}
/*
uint64_t Mod(uint64_t X, uint b, double qinv) {

	int i = 0;
	while (i < 10 && X > b) {
		uint64_t D = uint64_t(double(X) * qinv);
		if (D == 0) {D = 1;}
		uint64_t Y = D * b;
		X -= Y;
		i++;
	}
	//if (i > 1) Debug[1]++;
	if (X == b) {X = 0;}
	return X;
}
*/

bool tf(uint128 k) {
	uint128 sq, q;

	int top = int(findMSB(P));

	// q = 2 * p * k + 1
	//pp.Lo = P;
	//pp.Hi = 0;
	Mul128(k, P, q);
	Lsh(q);
	Inc(q);

        // Make our 1/q just a tiny bit too small, so we don't over estimate,
        // but not so small as to need extra passes.
	double qinv = 0.99999999999999 / toF(q);

	// Do the TF math: Starting with 1, repeatedly square,
	//  remove the top bit of the exponent and if 1 multiply squared value by 2,
	//  then compute mod Q.
	uint64_t one = 1L;
	sq.Lo = 1; sq.Hi = 0;
	for (int b = top; b >= 0; b--) {
		bool bb = (P & (one << b)) != 0;
		SqModXX(sq, q, bb, qinv);
	}
	// If the result is 1, then we found a factor.
	return sq.Lo == 1 && sq.Hi == 0;
}

void main() {
	//uint I = gl_GlobalInvocationID.x;
	if (Init == 0) {
		while (true) {
			uint i = atomicAdd(L, 1);
			if (i >= M) {
				// All threads return here.
				return;
			}
			uint64_t p64 = P;
			uint64_t q = (p64) * 2 * i + 1;
			bool x = (((q&7) == 3) || ((q&7) == 5) || (q%3 == 0) ||
				  (q%5 == 0) || (q%7 == 0) || (q%11 == 0) || (q%13 == 0) ||
				  (q%17 == 0) || (q%19 == 0) || (q%23 == 0));
			if (!x) {
				uint o = atomicAdd(Ll, 1);
				List[o] = i;
			}
			//
			// this table allows a 12% speedup later
			//
			if (i < M2) {
				X2[i] = ! (((q % 29) == 0 ||(q % 31) == 0 ||
					    (q % 37) == 0||(q % 41) == 0 || (q % 43) == 0));
			}
		}
		// no threads reach here.
	}
	//
	// K is the base starting value for this invocation. 
	//
	uint128 k;
	k.Lo = K[0];
	k.Hi = K[1];

	while (true) {
		// get the next index from the List to test
		uint i = atomicAdd(L, 1);
		if (i >= Ll) {
			return;
		}
		uint o = List[i];
		uint128 oo;

		//
		// this test gives a speedup of about 12%.
		// the if-branch itself and mod M2 are fairly expensive
		//
		if (X2[(o + KmodM2)%M2] == false) {
			//uint x = atomicAdd(Debug[0], 1);
			continue;
		}

		// offset from the base K
		oo.Lo = o;
		oo.Hi = 0;

		// the actual K this thread will test.
		Add(k, oo);

		// check if something went terribly wrong above.
		// We didn't find a K to test at all?
		if (Zero(k)) {return;}
		//return;
		
		if (tf(k)) {
			// How many have we found?
			uint f = atomicAdd(Debug[1], 1);
			// return the 96-bit K
			Found[f][0] = k.Lo;
			Found[f][1] = k.Hi;
			//Found[f][2] = k.x[2];
		}
		return;
	}
}
