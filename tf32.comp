#version 460
// We aren't using any of these, but just in case we want to later...
//#extension GL_ARB_separate_shader_objects : enable
//#extension GL_ARB_gpu_shader_int64 : enable
//#extension GL_EXT_debug_printf : enable
//#extension GL_KHR_shader_subgroup_vote : enable
//#extension GL_EXT_shader_explicit_arithmetic_types_int8 : enable
//#extension GL_EXT_shader_explicit_arithmetic_types_int16 : enable
#extension GL_EXT_shader_explicit_arithmetic_types_int64 : enable
#extension GL_EXT_shader_atomic_int64: enable

// This SPIR-V from this file is compiled into the gvtf binary, selected with version=32
//
// compile this file into SPIR-V with:
//   glslangValidator --target-env vulkan1.3 -V tf.comp
// or
//   glslc --target-env=vulkan1.3 tf.comp -o comp.spv
// glslc might produce slightly faster SPIR-V for the Radeon VII
//
// update: 32-bit version doesn't need to be compiled with 1.3, just use:
//   glslangValidator  -V tf.comp
//
// Installing the 'vulkan-amdgpu' package will result in a significant (2.5x) performance increase.
// also, maybe the difference isn't so much when not using uint64_t math.
//

#define M (4 * 3 * 5 * 7 * 11 * 13 * 17 * 19 * 23) // 446,185,740
#define M2 (29 * 31 * 37 * 41 * 43)                 //  58,642,669
#define M3 (47 * 53 * 59 * 61)                      //   8,965,109
#define M4 (67 * 71 * 73 * 79)                      //  27,433,619
#define M5 (83 * 89 * 97 * 101)                     //  72,370,439
#define M6 (103 * 107 * 109 * 113)                  // 135,745,657
#define M7 (127 * 131 * 137 * 139)                  // 316,818,391
#define M8 (149 * 151 * 157)
#define M9 (163 * 167 * 173)                        //   4,709,233
#define M0 (179 * 181 * 191)                        //   6,188,209
#define M1 (193 * 197 * 199)                        //   7,566,179

#define ListN 72990720
//#define ListN 2043740170
layout (local_size_x = 64) in;

// This is allocated in HOST_VISIBLE_LOCAL memory, and is shared with host.
// it is somewhat slow, compared to DEVICE_LOCAL memory.
layout(binding = 0) buffer buf
{	
	uint64_t    P;          // input from CPU side
	uint        Init;       // If this is 1, then we setup our tables once.
	uint        Big;        // Need > 96-bit math
	uint64_t    K[2];       // base K input from CPU side
	uint64_t    Found[10][2];   // output to tell the CPU we found a K resulting in a factor
	uint        NFound;
	uint        Debug[4];   // output only used for debugging
	uint        L3;
	uint        Test[1000];
};

struct uint96 {
	uvec3 x;
};

struct uint192 {
	uint96 H;
	uint96 L;
};

// This is allocated in DEVICE_LOCAL memory, not shared with host.  See CPU code to see how this is allocated.
// This is much faster to access from the shader, especially if the GPU is in a PCIx1 slot.
layout(binding = 1) buffer buf2
{
	uint    xL, xL2, xLl;
	int        PreTop;
	uint96     PreSq;
	uint       List[ListN];
	uint       List2[ListN];
	uint    X2[1+M2/32];
	uint    X3[1+M3/32];
	uint    X4[1+M4/32];
	uint    X5[1+M5/32];
	uint    X6[1+M6/32];
	uint    X7[1+M7/32];
	uint    X8[1+M8/32];
	uint    X9[1+M9/32];
	uint    X0[1+M0/32];
	uint    X1[1+M1/32];
};

bool Zero(uint96 A) {
	return A.x[0] == 0 && A.x[1] == 0 && A.x[2] == 0;
}
bool Zero(uint192 A) {
	return Zero(A.L) && Zero(A.H);
}

void Lsh(inout uint96 A) {
	uint c0 = A.x[0] & (uint(1) << 31);
	uint c1 = A.x[1] & (uint(1) << 31);
	A.x[0] <<= 1;
	A.x[1] <<= 1;
	A.x[1] |= c0 >> 31;
	A.x[2] <<= 1;
	A.x[2] |= c1 >> 31;
}
void Lsh(inout uint192 A) {
	
	uint c = A.L.x[2] & (uint(1) << 31);
	Lsh(A.L);
	Lsh(A.H);
	A.H.x[0] |= c >> 31;
}
int Cmp(uint96 A, uint B) {
	if (A.x[2] > 0) {return 1;}
	if (A.x[1] > 0) {return 1;}
	if (A.x[0] > B) {return 1;}
	if (A.x[0] < B) {return -1;}
	return 0;
}
int Cmp(uint96 A, uint96 B) {
	if (A.x[2] > B.x[2]) {return 1;}
	if (A.x[2] < B.x[2]) {return -1;}
	if (A.x[1] > B.x[1]) {return 1;}
	if (A.x[1] < B.x[1]) {return -1;}
	if (A.x[0] > B.x[0]) {return 1;}
	if (A.x[0] < B.x[0]) {return -1;}
	return 0;
}
int Cmp(uint192 A, uint96 B) {
	if (Zero(A.H)) {
		return Cmp(A.L, B);
	} else {
		if (Zero(B)) {
			return 0;
		}
		return 1;
	}
}
int Cmp(uint192 A, uint192 B) {
	int c = Cmp(A.H, B.H);
	if (c != 0) {
		return c;
	}
	return Cmp(A.L, B.L);
}
void Inc(inout uint96 A) {
	A.x[0] += 1;
	if (A.x[0] == 0) {
		A.x[1] += 1;
		if (A.x[1] == 0) {
			A.x[2] += 1;
		}
	}
}
void Inc(inout uint192 A) {
	Inc(A.L);
	if (Zero(A.L)) {
		Inc(A.H);
	}
}
void Add(inout uint96 A, uint B) {
	uint C;
	A.x[0] = uaddCarry(A.x[0], B, C);
	A.x[1] = uaddCarry(A.x[1], C, C);
	A.x[2] += C;
}
void Add(inout uint96 A, uint96 B) {
	uint c, c1;
	A.x[0] = uaddCarry(A.x[0], B.x[0], c);
	A.x[1] = uaddCarry(A.x[1], c, c1);
	A.x[1] = uaddCarry(A.x[1], B.x[1], c);
	A.x[2] = A.x[2] + B.x[2] + c + c1;

}
void Subxx(inout uint192 A, uint192 B) {

	uint c;
	/// XXX this doesn't work, what about +c that overflows?  rare, but still fix it.
	A.L.x[0] = usubBorrow(A.L.x[0], B.L.x[0], c);
	A.L.x[1] = usubBorrow(A.L.x[1], B.L.x[1]+c, c);
	A.L.x[2] = usubBorrow(A.L.x[2], B.L.x[2]+c, c);	
	A.H.x[0] = usubBorrow(A.H.x[0], B.H.x[0]+c, c);	
	A.H.x[1] = usubBorrow(A.H.x[1], B.H.x[1]+c, c);	
	A.H.x[2] = usubBorrow(A.H.x[2], B.H.x[2]+c, c);	
}
void Sub(inout uint192 A, uint192 B) {

	uint c, c1;
	
	A.L.x[0] = usubBorrow(A.L.x[0], B.L.x[0], c);
	A.L.x[1] = usubBorrow(A.L.x[1], c, c1);
	A.L.x[1] = usubBorrow(A.L.x[1], B.L.x[1], c);

	A.L.x[2] = usubBorrow(A.L.x[2], c+c1, c);
	A.L.x[2] = usubBorrow(A.L.x[2], B.L.x[2], c1);

	A.H.x[0] = usubBorrow(A.H.x[0], c+c1, c);
	A.H.x[0] = usubBorrow(A.H.x[0], B.H.x[0], c1);	

	A.H.x[1] = usubBorrow(A.H.x[1], c+c1, c);	
	A.H.x[1] = usubBorrow(A.H.x[1], B.H.x[1], c1);	

	A.H.x[2] = usubBorrow(A.H.x[2], B.H.x[2]+c+c1, c);	
}
void Sub(inout uint96 A, uint96 B) {

	uint c, c1;
	
	A.x[0] = usubBorrow(A.x[0], B.x[0], c);
	A.x[1] = usubBorrow(A.x[1], c, c1);
	A.x[1] = usubBorrow(A.x[1], B.x[1], c);

	A.x[2] = usubBorrow(A.x[2], c+c1, c);
	A.x[2] = usubBorrow(A.x[2], B.x[2], c1);
}


// 2^64, 2^128 and 2^192
const   double p32 =  4294967296.0lf;
const 	double p64 =  18446744073709551616.0lf;
const   double p96 =  79228162514264337593543950336.0lf;
const	double p128 = 340282366920938463463374607431768211456.0lf;
const   double p160 = 1461501637330902918203684832716283019655932542976.0lf;
//const	double p192 = 6277101735386680763835789423207666416102355444464034512896.0lf;

double toF(uint96 A) {
	return double(A.x[0]) + double(A.x[1]) * p32 + double(A.x[2]) * p64;
}
double toF(uint192 A) {
	return double(A.L.x[0]) + double(A.L.x[1]) * p32 + double(A.L.x[2]) * p64 +
		double(A.H.x[0]) * p96 + double(A.H.x[1]) * p128 + double(A.H.x[2]) * p160;
}
void fto96x(double f, out uint96 A) {
	A.x[2] = uint(f / p64);
	A.x[1] = uint((f - double(A.x[2]) * p64) / p32);
	A.x[0] = uint(f - (double(A.x[2]) * p64 + double(A.x[1]) * p32));
}
void fto96(double f, out uint96 A) {
	uint x = uint(f / p64);
	A.x[2] = x;
	uint y = uint((f - x * p64) / p32);
	A.x[1] = y;
	A.x[0] = uint(f - (x * p64 + y * p32));
}

void Mul192(inout uint96 A, uint96 B, out uint192 R)
{
	uint h[9], l[9];
	uint c1, c2, c;

	umulExtended(A.x[0], B.x[0], h[0], l[0]);
	umulExtended(A.x[0], B.x[1], h[1], l[1]);
	umulExtended(A.x[0], B.x[2], h[2], l[2]);
	umulExtended(A.x[1], B.x[0], h[3], l[3]);
	umulExtended(A.x[1], B.x[1], h[4], l[4]);
	umulExtended(A.x[1], B.x[2], h[5], l[5]);
	umulExtended(A.x[2], B.x[0], h[6], l[6]);
	umulExtended(A.x[2], B.x[1], h[7], l[7]);
	umulExtended(A.x[2], B.x[2], h[8], l[8]);

	R.L.x[0] = l[0];
	R.L.x[1] = uaddCarry(h[0], l[1], c1);	c = c1;
	R.L.x[1] = uaddCarry(R.L.x[1], l[3], c1);	c += c1;

	R.L.x[2] = uaddCarry(l[2], c, c1);	c = c1;
	R.L.x[2] = uaddCarry(R.L.x[2], h[1], c1);	c += c1;
	R.L.x[2] = uaddCarry(R.L.x[2], h[3], c1);	c += c1;
	R.L.x[2] = uaddCarry(R.L.x[2], l[4], c1);	c += c1;
	R.L.x[2] = uaddCarry(R.L.x[2], l[6], c1);	c += c1;

	R.H.x[0] = uaddCarry(l[5], c, c1);	c = c1;
	R.H.x[0] = uaddCarry(R.H.x[0], h[2], c1);	c += c1;
	R.H.x[0] = uaddCarry(R.H.x[0], h[4], c1);	c += c1;
	R.H.x[0] = uaddCarry(R.H.x[0], l[7], c1);	c += c1;
	R.H.x[0] = uaddCarry(R.H.x[0], h[6], c1);	c += c1;

	R.H.x[1] = uaddCarry(h[5], c, c1);	c = c1;
	R.H.x[1] = uaddCarry(R.H.x[1], l[8], c1);	c += c1;
	R.H.x[1] = uaddCarry(R.H.x[1], h[7], c1);	c += c1;
	R.H.x[2] = uaddCarry(h[8], c, c1);
}

uint Mod(uint96 X, uint Q) {
	if (X.x[2] == 0) {
		uint64_t x64 = X.x[0] | uint64_t(X.x[1]) << 32;
		return uint(x64 % Q);
	}
	//atomicAdd(Debug[0], 1);
	uint96 D, QQ;
	uint192 Y;
	int i = 0;
	double qinv = 0.9999999999999 / double(Q);
	QQ.x = uvec3(Q, 0, 0);
	while (i < 10 && Cmp(X, Q) > 0) {
		double x = toF(X);
		double xqi = x * qinv;
		fto96(xqi, D);
		if (Zero(D)) {
			D.x[0] = 1;
		}
		Mul192(D, QQ, Y);
		Sub(X, Y.L);
		i++;
	}
	if (X.x[0] == Q) return 0;
	return X.x[0];
}
bool Mod0(uint96 X, uint Q) {
	if (X.x[2] == 0) {
		uint64_t x64 = X.x[0] | uint64_t(X.x[1]) << 32;
		return (x64 % Q) == 0;
	}
	uint96 D, QQ;
	uint192 Y;
	int i = 0;
	double qinv = 0.9999999999999 / double(Q);
	QQ.x = uvec3(Q, 0, 0);
	while (i < 10 && Cmp(X, Q) > 0) {
		double x = toF(X);
		double xqi = x * qinv;
		fto96(xqi, D);
		if (Zero(D)) {
			D.x[0] = 1;
		}

		Mul192(D, QQ, Y);
		Sub(X, Y.L);
		i++;
	}
	return Zero(X) || X == QQ;
}

// 192-bit Floating point version
void SqMod(inout uint96 A, uint96 Q, bool doshift, double qinv) {
	uint192 X, Y;
	uint96 D;

	Mul192(A, A, X);
	if (doshift) {
		Lsh(X);
	}

	// it is faster to do this w/o testing, even if D might be zero and have no effect.
	if (true) {
		fto96(toF(X)*qinv, D);
		Mul192(D, Q, Y);
		Sub(X, Y);

		fto96(toF(X)*qinv, D);
		Mul192(D, Q, Y);
		Sub(X, Y);
	}
	int i = 0; // limit to 10, in case we have a bug, don't want to get stuck...

	// Using floating point, take a guess at a number D such that we could subtract D*Q to leave our remander.
	// Always guess D a little low, and refine our guess as we get closer.
	// normally takes 2 passes.
	//
	//while (i < 5 && Cmp(X, Q) > 0) {
	while (Cmp(X, Q) > 0) {
		fto96(toF(X)*qinv, D);
		if (Zero(D)) {
			D.x[0] = 1;
		}
		Mul192(D, Q, Y);
		Sub(X, Y);
		i++;
	}
	if (i > 1) {
		//atomicAdd(Debug[0], 1);
	}
	A = X.L;
}

void to96(uint64_t n, inout uint96 o) {
	uint p0 = uint(n);      // lower 32-bits
	uint p1 = uint(n>>32);  // upper 32-bits
	o.x = uvec3(p0, p1, 0);
}

bool tf(uint96 k) {
	uint96 sq, q, pp;
	uint192 t;

	//int top = int(findMSB(P));
	// q = 2 * p * k + 1
	to96(P, pp);
	Mul192(k, pp, t);
	q = t.L;  // q is limited to 96-bits
	Lsh(q);
	Inc(q);

        // Make our 1/q just a tiny bit too small, so we don't over estimate,
        // but not so small as to need extra passes.
	double qinv = 0.9999999999999 / toF(q);

	// Do the TF math: Starting with 1, repeatedly square,
	//  remove the top bit of the exponent and if 1 multiply squared value by 2,
	//  then compute mod Q.
	uint64_t one = 1L << PreTop;
	sq.x = uvec3(1, 0, 0);
	sq = PreSq; // Start from the pre-computed point
	for (int b = PreTop; b >= 0; b--) {
		bool bb = (P & (one)) != 0;
		one >>= 1;
		SqMod(sq, q, bb, qinv);
	}
	// If the result is 1, then we found a factor.
	return sq.x[0] == 1 && sq.x[1] == 0 && sq.x[2] == 0;
}

//
// The squaring rounds are all the same, until Sq>Q.  So we can pre-compute those.
//
void pretf(uint96 k) {
	uint96 sq, q, pp;
	uint192 t;

	int top = int(findMSB(P));
	// q = 2 * p * k + 1
	to96(P, pp);
	Mul192(k, pp, t);
	q = t.L;  // q is limited to 96-bits
	Lsh(q);
	Inc(q);

	uint192 X;
	// Do the TF math: Starting with 1, repeatedly square,
	//  remove the top bit of the exponent and if 1 multiply squared value by 2,
	//  precompute until sq > q.
	uint64_t one = 1L;
	sq.x = uvec3(1, 0, 0);
	for (int b = top; b >= 0; b--) {
		bool bb = (P & (one << b)) != 0;
		Mul192(sq, sq, X);
		if (bb) {
			Lsh(X);
		}
		if (Cmp(X, q) > 0) {
			break;
		}
		// later we start from this point.
		sq = X.L;
		PreTop = b-1;
		PreSq = sq;
	}
}


void main() {
	//uint I = gl_GlobalInvocationID.x;
	//
	// K is the base starting value for this invocation. 
	//
	uint96 kbase;
	kbase.x = uvec3(uint(K[0]& 0xffffffff), uint((K[0]>>32)& 0xffffffff), uint(K[1]&0xffffffff));

	// copy some counters back to shared memory
	if (Init == 5) {
		uint I = gl_GlobalInvocationID.x;
		if (I == 0) {
			Debug[0] = xLl;
			Debug[1] = xL2;
		}
		return;
	}
	// initialize atomic counters for the next invocation.
	if (Init >= 10) {
		if (gl_GlobalInvocationID.x == 0) {
			Debug[0] = 0;
			Debug[1] = 0;
			Debug[2] = 0;
			Debug[3] = 0;
			xL = 0;
			L3 = 0;
			NFound = 0;
			if (Init == 12) {
				xL2 = 0;
			}
			if (Init == 11) {
				xLl = 0;
			}
		}
		return;
	}

	// TF run
	if (Init == 0) {
		if (Big > 0) {
			// this version can't handle >96bit
			Debug[3] = 1;
			return;
		}
		while (true) {
			// get the next index from the List to test
			uint i = atomicAdd(xL, 1);
			if (i >= xL2) {
				return;
			}
			uint96 k = kbase;
			uint o = List2[i];

			// XXX: code is faster with this line, even if the condition is never true, weird
			// something magic about the possibility of a continue.
			// doesn't really matter what the condition is.
			if (o == 0 && Zero(k)) {continue;}

			// the actual K this thread will test.
			Add(k, o);

			if (tf(k)) {
				// How many have we found?
				uint f = atomicAdd(NFound, 1);
				// return the 96-bit K
				Found[f][0] = k.x[0] | uint64_t(k.x[1]) << 32;
				Found[f][1] = k.x[2];
			}
		}
	}

 	// perform the second sieve, populating list2
	if (Init == 2) {
		uint I = gl_GlobalInvocationID.x;
		if (I == 0) {
			uint96 kt = kbase;
			Inc(kt);  // incase of 0.
			pretf(kt);
			//return;
		}
		uint kmodm2 = Mod(kbase, M2);
		uint kmodm3 = Mod(kbase, M3);
		uint kmodm4 = Mod(kbase, M4);
		uint kmodm5 = Mod(kbase, M5);
		uint kmodm6 = Mod(kbase, M6);
		uint kmodm7 = Mod(kbase, M7);
		uint kmodm8 = Mod(kbase, M8);
		uint kmodm9 = Mod(kbase, M9);
		uint kmodm0 = Mod(kbase, M0);
		uint kmodm1 = Mod(kbase, M1);

		while (true) {
			uint i = atomicAdd(xL, 1);

			uint o = List[i];
			if (i >= xLl) { return; }
			if (i > M) {continue;} // non-sense code, helps optimizer

			uint i2 = (o + kmodm2)%M2;
			bool c2 = 0 == (X2[i2/32] & (1u << (i2%32)));
			uint i3 = (o + kmodm3)%M3;
			bool c3 = 0 == (X3[i3/32] & (1u << (i3%32)));
			uint i4 = (o + kmodm4)%M4;
			bool c4 = 0 == (X4[i4/32] & (1u << (i4%32)));
			uint i5 = (o + kmodm5)%M5;
			bool c5 = 0 == (X5[i5/32] & (1u << (i5%32)));
			uint i6 = (o + kmodm6)%M6;
			bool c6 = 0 == (X6[i6/32] & (1u << (i6%32)));
			uint i7 = (o + kmodm7)%M7;
			bool c7 = 0 == (X7[i7/32] & (1u << (i7%32)));
			uint i8 = (o + kmodm8)%M8;
			bool c8 = 0 == (X8[i8/32] & (1u << (i8%32)));
			uint i9 = (o + kmodm9)%M9;
			bool c9 = 0 == (X9[i9/32] & (1u << (i9%32)));
			uint i0 = (o + kmodm0)%M0;
			bool c0 = 0 == (X0[i0/32] & (1u << (i0%32)));
			uint i1 = (o + kmodm1)%M1;
			bool c1 = 0 == (X1[i1/32] & (1u << (i1%32)));
			if (c2 && c3 && c4 && c5 && c6 && c7 && c8 && c9 && c0 && c1)
			{
			     	uint ii = atomicAdd(xL2, 1);
				List2[ii] = List[i];
			} else if (false) {
				// Give a sample of composites back to the CPU for primality testing.
				// This is just for looking for bugs in the sieving process.
			     	uint ii = atomicAdd(L3, 1);
				if (ii < 1000) {
					Test[ii] = List[i];
				}
			}
		}
		return;
	}
	// initialize our bit arrays to zero
	if (Init == 3) {
		while (true) {
			uint i = atomicAdd(xL, 1);
			if (i > 1+M7/32) {
				// All threads return here.
				return;
			}
			if (i <= M2/32) {
				X2[i] = 0;
			}
			if (i <= M3/32) {
				X3[i] = 0;
			}
		       	if (i <= M4/32) {			     
				X4[i] = 0;
			}
			if (i <= M5/32) {			     
				X5[i] = 0;
			}
			if (i <= M6/32) {			     
				X6[i] = 0;
			}
			if (i <= M7/32) {
				X7[i] = 0;
			}
			if (i <= M8/32) {
				X8[i] = 0;
			}
			if (i <= M9/32) {
				X9[i] = 0;
			}
			if (i <= M0/32) {
				X0[i] = 0;
			}
			if (i <= M1/32) {
				X1[i] = 0;
			}
		}
	}
	// perform the first sieve
	if (Init == 1) {
		while (true) {
			uint i = atomicAdd(xL, 1);
			if (i >= M) {
				// All threads return here.
				return;
			}
			uint96 K, Q, pp;
			uint192 t;
			to96(P, pp);
			K.x = uvec3(i, 0, 0);
			Mul192(K, pp, t);
			Q = t.L;  // q is limited to 96-bits
			Lsh(Q);
			Inc(Q);

			uint qa7 = Q.x[0] & 7;
			bool y = (qa7 == 3) || (qa7 == 5) || Mod0(Q,3) ||
				Mod0(Q,5) || Mod0(Q,7) || Mod0(Q,11) || Mod0(Q,13) ||
				Mod0(Q,17) || Mod0(Q,19) || Mod0(Q,23);
			if (!y) {
				uint o = atomicAdd(xLl, 1);
				List[o] = i;
			}
			if (i < M2) {
				bool c = (Mod0(Q,29)||Mod0(Q,31) || Mod0(Q,37)||Mod0(Q,41) || Mod0(Q,43));
				if (c) {
					atomicOr(X2[i/32], 1u << (i%32));
				}
			}
			if (i < M3) {
				bool c = (Mod0(Q,47)||Mod0(Q,53) || Mod0(Q,59)||Mod0(Q,61));
				if (c) {
					atomicOr(X3[i/32], 1u << (i%32));
				}
			}
		       	if (i < M4) {			     
				bool c = (Mod0(Q,67)||Mod0(Q,71) || Mod0(Q,73)||Mod0(Q,79));
				if (c) {
					atomicOr(X4[i/32], 1u << (i%32));
				}
			}
			if (i < M5) {			     
				bool c = (Mod0(Q,83)||Mod0(Q,89) || Mod0(Q,97)||Mod0(Q,101));
				if (c) {
					atomicOr(X5[i/32], 1u << (i%32));
				}
			}
			if (i < M6) {			     
				bool c = (Mod0(Q,103)||Mod0(Q,107) || Mod0(Q,109)||Mod0(Q,113));
				if (c) {
					atomicOr(X6[i/32], 1u << (i%32));
				}
			}
			if (i < M7) {
				bool c = (Mod0(Q,127)||Mod0(Q,131) || Mod0(Q,137)||Mod0(Q,139));
				if (c) {
					atomicOr(X7[i/32], 1u << (i%32));
				}
			}
			if (i < M8) {
				bool c = (Mod0(Q,149)||Mod0(Q,151) || Mod0(Q,157));
				if (c) {
					atomicOr(X8[i/32], 1u << (i%32));
				}
			}
			if (i < M9) {
				bool c = (Mod0(Q,163)||Mod0(Q,167) || Mod0(Q,173));
				if (c) {
					atomicOr(X9[i/32], 1u << (i%32));
				}
			}
			if (i < M0) {
				bool c = (Mod0(Q,179)||Mod0(Q,181) || Mod0(Q,191));
				if (c) {
					atomicOr(X0[i/32], 1u << (i%32));
				}
			}
			if (i < M1) {
				bool c = (Mod0(Q,193)||Mod0(Q,197) || Mod0(Q,199));
				if (c) {
					atomicOr(X1[i/32], 1u << (i%32));
				}
			}
		}
		// no threads reach here.
		return;
	}

}
